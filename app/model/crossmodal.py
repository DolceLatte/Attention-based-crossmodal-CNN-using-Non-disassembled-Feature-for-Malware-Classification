import torch
import torch.nn as nn
from torchsummary import summary

use_cuda = torch.cuda.is_available()

class Attention(nn.Module):
    def __init__(self, input_dim,hidden_size):
        super(Attention, self).__init__()
        self.hidden_size = hidden_size
        self.linear = nn.Linear(input_dim, hidden_size, bias=False)
        self.softmax = nn.Softmax(dim=-1)

    def forward(self, h_src, h_t_tgt, mask=None):
        # |h_src| = (batch_size, length, hidden_size)
        # |h_t_tgt| = (batch_size, length, hidden_size)
        h_t_tgt = h_t_tgt.transpose(1, 2).contiguous()
        query = self.linear(h_t_tgt)
        # |query| = (batch_size, hidden_size, length)
        weight = torch.bmm(query, h_src)

        # |weight| = (batch_size, tgt_len, src_len)

        if weight.shape[1] == 784:
            #src : structural entropy 64, 3600
            # tgt,query : malware image 784, 64
            # weight shape : 784, 3600
            # maks shape :  3600, 1
            mask = mask.transpose(1, 2).repeat(1, 784, 1)
            weight.data.masked_fill_(mask == 0, -float('inf'))
            # |weight| = (batch_size, tgt_length, length)
            weight = self.softmax(weight)

            context_vector = torch.bmm(weight, h_src.transpose(1, 2))
            return context_vector.transpose(1, 2)

        elif weight.shape[1] == 3600:
            # src : malware image 64, 784
            # tgt,query : structural entropy 3600, 64
            # weight shape : 3600, 784
            # maks shape :  3600, 1
            weight = self.softmax(weight)
            context_vector = torch.bmm(weight, h_src.transpose(1, 2))
            mask = mask.repeat(1, 1, 64)
            context_vector.data.masked_fill_(mask == 0, float(0))
            return context_vector.transpose(1, 2)
        
        
class CrossmodalNet(nn.Module):
    def __init__(self):
        # 항상 torch.nn.Module을 상속받고 시작
        super(CrossmodalNet, self).__init__()
        input_dim = hidden_size = 64
        conv1 = nn.Conv1d(in_channels=128, out_channels=70, kernel_size=3)
        # activation ReLU
        pool1 = nn.MaxPool1d(2)

        conv2 = nn.Conv1d(in_channels=70, out_channels=70, kernel_size=3)
        # activation ReLU
        pool2 = nn.MaxPool1d(2)

        conv3 = nn.Conv1d(in_channels=70, out_channels=70, kernel_size=3)
        # activation ReLU
        pool3 = nn.MaxPool1d(2)
        conv4 = nn.Conv1d(in_channels=70, out_channels=70, kernel_size=3)
        # activation ReLU
        pool4 = nn.MaxPool1d(2)
        '''
        Caculate conv1d of malware image
        '''
        conv1_img = nn.Conv1d(in_channels=128, out_channels=70, kernel_size=3)
        pool1_img = nn.MaxPool1d(2)
        conv2_img = nn.Conv1d(in_channels=70, out_channels=70, kernel_size=3)
        # activation ReLU
        pool2_img = nn.MaxPool1d(2)
        conv3_img = nn.Conv1d(in_channels=70, out_channels=70, kernel_size=3)
        # activation ReLU
        pool3_img = nn.MaxPool1d(2)
        conv4_img = nn.Conv1d(in_channels=70, out_channels=70, kernel_size=3)
        # activation ReLU
        pool4_img = nn.MaxPool1d(2)

        self.conv_e = nn.Conv1d(in_channels=14, out_channels=hidden_size, kernel_size=1,stride=1)
        self.conv_e_img = nn.Conv1d(in_channels=64, out_channels=hidden_size, kernel_size=1,stride=1)
        self.attn = Attention(input_dim,hidden_size)
        self.attn_img = Attention(input_dim,hidden_size)

        self.conv_module = nn.Sequential(
            conv1,
            nn.BatchNorm1d(70, affine=True),
            nn.ReLU(),
            pool1,
            conv2,
            nn.BatchNorm1d(70, affine=True),
            nn.ReLU(),
            pool2,
            conv3,
            nn.BatchNorm1d(70, affine=True),
            nn.ReLU(),
            pool3,
            conv4,
            nn.BatchNorm1d(70,affine=True),
            nn.ReLU(),
            pool4,
        )

        self.conv_module_img = nn.Sequential(
            conv1_img,
            nn.BatchNorm1d(70, affine=True),
            nn.ReLU(),
            pool1_img,
            conv2_img,
            nn.BatchNorm1d(70, affine=True),
            nn.ReLU(),
            pool2_img,
            conv3_img,
            nn.BatchNorm1d(70, affine=True),
            nn.ReLU(),
            pool3_img,
            conv4_img,
            nn.BatchNorm1d(70, affine=True),
            nn.ReLU(),
            pool4_img,
        )

        self.generator = nn.Sequential(
            nn.Linear(18900, 1000),
            nn.Linear(1000, 300),
            nn.Linear(300, 9),
        )

        # gpu로 할당
        if use_cuda:
            self.conv_module = self.conv_module.cuda()
            self.conv_module_img = self.conv_module_img.cuda()
            self.generator = self.generator.cuda()

            self.attn = self.attn.cuda()
            self.attn_img = self.attn_img.cuda()

            self.conv_e = self.conv_e.cuda()
            self.conv_e_img = self.conv_e_img.cuda()


    def forward(self, x , x_img, mask):
        e_x = self.conv_e(x)
        e_x_img = self.conv_e_img(x_img)

        x_attn_img, att_score = self.attn(e_x_img, e_x, mask)

        x_attn, _ = self.attn_img(e_x, e_x_img, mask)

        x = torch.cat([e_x, x_attn_img], dim=1)
        x_img = torch.cat([e_x_img, x_attn], dim=1)

        out = self.conv_module(x)
        out_img = self.conv_module_img(x_img)

        out = torch.flatten(out, 1)
        out_img = torch.flatten(out_img, 1)

        out = torch.cat([out, out_img], dim=-1)
        #print(out.shape)
        y = self.generator(out)
        return y,  att_score

def weight_init(m):
    if isinstance(m, nn.Conv1d):
        nn.init.kaiming_uniform_(m.weight)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.BatchNorm1d):
        nn.init.constant_(m.weight, 1)
        nn.init.constant_(m.bias, 0)

    elif isinstance(m, nn.Linear):
        nn.init.kaiming_uniform_(m.weight)
        nn.init.constant_(m.bias, 0)
        
import numpy as np

if __name__ == '__main__':
    cnn = CrossmodalNet()
    # img = torch.tensor(np.zeros((128,64,784)),dtype=torch.float32,device=0)
    # x = torch.tensor(np.zeros((128,14,3600)),dtype=torch.float32,device=0)
    # cnn(x,img)
    summary(cnn, [(14,3600),(64,784)],batch_size=2)
